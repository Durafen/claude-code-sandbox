#!/bin/bash

# Sandboxed Claude Code CLI wrapper
# Based on https://github.com/cwensel/claude-sandbox/blob/main/claudes

# Function to generate random suffix
generate_random_suffix() {
    python3 -c "import random, string; print(''.join(random.choices(string.ascii_lowercase + string.digits, k=8)))"
}

# Define base image name (shared across all workspaces)
BASE_IMAGE_NAME="claude-code-sandbox-base"

# Function to get content hash for change detection
get_content_hash() {
    {
        # Hash Dockerfile content
        cat "$1/Dockerfile" 2>/dev/null || echo "no-dockerfile"
        # Hash .tool-versions if present
        cat ".tool-versions" 2>/dev/null || echo "no-tool-versions" 
    } | sha256sum | cut -d' ' -f1 | head -c 8
}

# Determine image name based on local .claude-code-sandbox file or create new one
SANDBOX_FILE=".claude-code-sandbox"
if [ -f "$SANDBOX_FILE" ]; then
    IMAGE_NAME=$(cat "$SANDBOX_FILE")
    echo "Using existing workspace image: $IMAGE_NAME"
else
    # Generate new image name with random suffix
    RANDOM_SUFFIX=$(generate_random_suffix)
    IMAGE_NAME="claude-code-sandbox-${RANDOM_SUFFIX}"
    echo "$IMAGE_NAME" > "$SANDBOX_FILE"
    echo "Created new workspace image: $IMAGE_NAME"
fi

# Parse command line options
BUILD_IMAGE=false
SHELL_MODE=true
NON_INTERACTIVE=false
DOCKER_ENABLED=false
INSTALL_TOOLS=""
CLEANUP_MODE=false
CLEANUP_DAYS=7
DRY_RUN=false
REBUILD_IMAGE=false
REMOVE_IMAGE=false
SYNC_CONFIG=false
CLAUDE_MODE=false
WORKTREE_BRANCH=""
CLEANUP_WORKTREE=false

while getopts "bsndc-:" opt; do
    case $opt in
        b)
            BUILD_IMAGE=true
            ;;
        s)
            SHELL_MODE=true
            ;;
        n)
            NON_INTERACTIVE=true
            ;;
        d)
            DOCKER_ENABLED=true
            ;;
        c)
            CLAUDE_MODE=true
            SHELL_MODE=false
            ;;
        -)
            case "${OPTARG}" in
                build)
                    BUILD_IMAGE=true
                    ;;
                install=*)
                    INSTALL_TOOLS="${OPTARG#*=}"
                    ;;
                shell)
                    SHELL_MODE=true
                    ;;
                non-interactive)
                    NON_INTERACTIVE=true
                    ;;
                docker)
                    DOCKER_ENABLED=true
                    ;;
                claude)
                    CLAUDE_MODE=true
                    SHELL_MODE=false
                    ;;
                cleanup)
                    CLEANUP_MODE=true
                    ;;
                sync-config)
                    SYNC_CONFIG=true
                    ;;
                older-than=*)
                    CLEANUP_DAYS="${OPTARG#*=}"
                    # Parse days from format like "7d", "3", "14d"
                    CLEANUP_DAYS="${CLEANUP_DAYS%d}"
                    ;;
                dry-run)
                    DRY_RUN=true
                    ;;
                rebuild)
                    REBUILD_IMAGE=true
                    BUILD_IMAGE=true
                    ;;
                remove)
                    REMOVE_IMAGE=true
                    ;;
                worktree-branch=*)
                    WORKTREE_BRANCH="${OPTARG#*=}"
                    if [ -z "$WORKTREE_BRANCH" ]; then
                        echo "Error: --worktree-branch requires a branch name" >&2
                        exit 1
                    fi
                    ;;
                cleanup-worktree)
                    CLEANUP_WORKTREE=true
                    ;;
                help)
                    echo "Claude Code Sandbox - Containerized development environment"
                    echo ""
                    echo "Usage: $0 [OPTIONS] [CLAUDE_ARGS...]"
                    echo ""
                    echo "Options:"
                    echo "  -b, --build                   Build/rebuild the Docker image"
                    echo "  -c, --claude                  Launch Claude Code"
                    echo "  -s, --shell                   Launch interactive shell (default)"
                    echo "  -n, --non-interactive CMD     Run non-interactive command"
                    echo "  -d, --docker                  Enable Docker access inside container"
                    echo "      --install=TOOLS           Install tools at build time"
                    echo "      --rebuild                 Force full rebuild without cache"
                    echo "      --remove                  Remove workspace image and state files"
                    echo "      --cleanup                 Remove old workspace images (default: 7+ days)"
                    echo "      --cleanup-worktree        Remove all git worktrees managed by this script"
                    echo "      --worktree-branch=BRANCH  Create/use a git worktree for the specified branch"
                    echo "      --sync-config             Sync host configs to sandbox (overwrites sandbox configs)"

                    echo "      --older-than=DAYS         Cleanup threshold (e.g. --older-than=3d)"
                    echo "      --dry-run                 Show what would be cleaned without doing it"
                    echo "      --help                    Show this help message"
                    echo ""
                    echo "Tool Installation:"
                    echo "  --install='tool1@version1,tool2@version2'"
                    echo ""
                    echo "Examples:"
                    echo "  $0 --build --install='python@3.12.8,golang@1.21.5'"
                    echo "  $0 --build --install='java@adoptopenjdk-17.0.2+8,terraform@1.5.7'"
                    echo "  $0 --rebuild                  # Force complete rebuild without cache"
                    echo "  $0 --remove                   # Remove current workspace image"
                    echo "  $0 --shell                    # Interactive shell"
                    echo "  $0 -n 'python --version'     # Non-interactive command"
                    echo "  $0 --cleanup                  # Remove images older than 7 days"
                    echo "  $0 --cleanup --older-than=3d  # Remove images older than 3 days"
                    echo "  $0 --cleanup --dry-run        # Preview cleanup without removing"
                    echo "  $0 --worktree-branch=feature  # Use a git worktree for 'feature' branch"
                    echo "  $0 --cleanup-worktree         # Remove all managed git worktrees"
                    echo ""
                    echo "Auto-completion:"
                    echo "  Bash: source ./completions/claude-code-sandbox"
                    echo "  Zsh:  Add ./completions to your fpath and run: autoload -U compinit && compinit"
                    echo ""
                    echo "For more information, see: README.md"
                    exit 0
                    ;;
                *)
                    echo "Unknown option --${OPTARG}" >&2
                    echo "Usage: $0 --build --install='plugin1@version1,plugin2@version2'"
                    echo "Examples:"
                    echo "  $0 --build --install='python@3.12.8,golang@1.21.5,maven@3.9.6'"
                    echo "  $0 --build --install='java@adoptopenjdk-17.0.2+8,terraform@1.5.7'"
                    echo "  $0 --build --install='nodejs@20.11.0,rust@1.75.0'"
                    echo "Use --help for more information"
                    exit 1
                    ;;
            esac
            ;;
        \?)
            echo "Invalid option: -$OPTARG" >&2
            exit 1
            ;;
    esac
done

shift $((OPTIND-1))

# Function to perform image cleanup
cleanup_images() {
    local days=$1
    local dry_run=$2
    local current_image=$(cat "$SANDBOX_FILE" 2>/dev/null || echo "")
    
    echo "=== Claude Code Sandbox Image Cleanup ==="
    echo "Looking for workspace images older than $days days..."
    echo "Current workspace image: $current_image"
    echo "Base image (always preserved): $BASE_IMAGE_NAME"
    echo ""
    
    # Get current timestamp in seconds
    local current_time=$(date +%s)
    local cutoff_time=$((current_time - (days * 24 * 3600)))
    
    # Find all claude-code-sandbox workspace images (exclude base)
    local images_to_check=$(docker images --format "{{.Repository}}\t{{.Tag}}\t{{.CreatedAt}}\t{{.Size}}\t{{.ID}}" | \
        grep "^claude-code-sandbox-" | grep -v "^$BASE_IMAGE_NAME")
    
    if [[ -z "$images_to_check" ]]; then
        echo "No workspace images found to clean up."
        return 0
    fi
    
    local images_to_remove=()
    local total_size=0
    
    echo "Scanning workspace images:"
    echo "Repository                        Created                Size      Image ID       Status"
    echo "----------------------------------------------------------------------------------------"
    
    # Process each image
    while IFS=$'\t' read -r repo tag created_at size image_id; do
        if [[ -z "$repo" ]]; then continue; fi
        
        # Use repo name directly (it should be the image name)
        local image_name="$repo"
        
        # Skip if this is the current workspace image
        if [[ "$image_name" == "$current_image" ]]; then
            printf "%-32s %-22s %-9s %-14s %s\n" "$repo" "$created_at" "$size" "$image_id" "(CURRENT - PRESERVED)"
            continue
        fi
        
        # Parse creation time - remove timezone for compatibility
        local clean_date=$(echo "$created_at" | sed 's/ -[0-9]* [A-Z]*$//')
        local image_time
        if command -v gdate >/dev/null 2>&1; then
            # macOS with coreutils
            image_time=$(gdate -d "$clean_date" +%s 2>/dev/null || echo 0)
        else
            # Linux date
            image_time=$(date -d "$clean_date" +%s 2>/dev/null || echo 0)
        fi
        
        if [[ $image_time -lt $cutoff_time ]]; then
            printf "%-32s %-22s %-9s %-14s %s\n" "$repo" "$created_at" "$size" "$image_id" "(MARKED FOR REMOVAL)"
            images_to_remove+=("$image_name")
            # Convert size to bytes for summing (rough estimate)
            local size_mb=$(echo "$size" | sed 's/[^0-9.]//g')
            if [[ -n "$size_mb" && "$size_mb" != "" ]]; then
                total_size=$((total_size + ${size_mb%.*}))
            fi
        else
            printf "%-32s %-22s %-9s %-14s %s\n" "$repo" "$created_at" "$size" "$image_id" "(TOO RECENT - PRESERVED)"
        fi
    done <<< "$images_to_check"
    
    echo ""
    
    if [[ ${#images_to_remove[@]} -eq 0 ]]; then
        echo "‚úÖ No images need cleanup (all are either current workspace, base image, or too recent)"
        return 0
    fi
    
    echo "üìã Summary:"
    echo "  Images to remove: ${#images_to_remove[@]}"
    echo "  Estimated space to reclaim: ~${total_size}MB"
    echo ""
    
    if [[ "$dry_run" == "true" ]]; then
        echo "üîç DRY RUN - No images will actually be removed"
        echo "Images that would be removed:"
        for image in "${images_to_remove[@]}"; do
            echo "  - $image"
        done
        return 0
    fi
    
    # Confirm removal
    echo "‚ö†Ô∏è  This will permanently remove ${#images_to_remove[@]} Docker images."
    echo "Are you sure you want to continue? (y/N)"
    read -r confirmation
    
    if [[ ! "$confirmation" =~ ^[Yy]$ ]]; then
        echo "‚ùå Cleanup cancelled"
        return 0
    fi
    
    echo ""
    echo "üóëÔ∏è  Removing images..."
    
    local removed_count=0
    for image in "${images_to_remove[@]}"; do
        echo "Removing: $image"
        if docker rmi "$image" >/dev/null 2>&1; then
            echo "  ‚úÖ Removed successfully"
            ((removed_count++))
        else
            echo "  ‚ö†Ô∏è  Failed to remove (might be in use)"
        fi
    done
    
    echo ""
    echo "‚úÖ Cleanup complete!"
    echo "  Successfully removed: $removed_count/${#images_to_remove[@]} images"
    
    if [[ $removed_count -gt 0 ]]; then
        echo ""
        echo "üí° Consider running 'docker system prune' to reclaim additional space from dangling images and build cache"
    fi
}

# Handle cleanup mode
if [[ "$CLEANUP_MODE" == true ]]; then
    cleanup_images "$CLEANUP_DAYS" "$DRY_RUN"
    exit 0
fi

# Sandbox config directory (persistent, protects host files)
SANDBOX_CONFIG_DIR="$HOME/.claude-sandbox"

# Function to sync host configs to sandbox (force mode overwrites existing)
sync_sandbox_config() {
    local force=${1:-true}  # Default to force mode for --sync-config
    echo "=== Syncing host configs to sandbox ==="
    mkdir -p "$SANDBOX_CONFIG_DIR"

    # Sync .claude directory (skip broken symlinks)
    if [ -d "$HOME/.claude" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.claude" ]; then
            echo "Syncing ~/.claude ..."
            rm -rf "$SANDBOX_CONFIG_DIR/.claude"
            mkdir -p "$SANDBOX_CONFIG_DIR/.claude"
            rsync -a --ignore-errors "$HOME/.claude/" "$SANDBOX_CONFIG_DIR/.claude/" 2>/dev/null
        fi
    fi

    # Sync .claude.json
    if [ -f "$HOME/.claude.json" ]; then
        if [ "$force" = true ] || [ ! -f "$SANDBOX_CONFIG_DIR/.claude.json" ]; then
            echo "Syncing ~/.claude.json ..."
            cp "$HOME/.claude.json" "$SANDBOX_CONFIG_DIR/.claude.json"
        fi
    fi

    # Sync .config/claude
    if [ -d "$HOME/.config/claude" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.config/claude" ]; then
            echo "Syncing ~/.config/claude ..."
            mkdir -p "$SANDBOX_CONFIG_DIR/.config"
            rm -rf "$SANDBOX_CONFIG_DIR/.config/claude"
            cp -r "$HOME/.config/claude" "$SANDBOX_CONFIG_DIR/.config/claude"
        fi
    fi

    # Sync .anthropic
    if [ -d "$HOME/.anthropic" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.anthropic" ]; then
            echo "Syncing ~/.anthropic ..."
            rm -rf "$SANDBOX_CONFIG_DIR/.anthropic"
            cp -r "$HOME/.anthropic" "$SANDBOX_CONFIG_DIR/.anthropic"
        fi
    fi

    # Sync .config/opencode
    if [ -d "$HOME/.config/opencode" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.config/opencode" ]; then
            echo "Syncing ~/.config/opencode ..."
            mkdir -p "$SANDBOX_CONFIG_DIR/.config"
            rm -rf "$SANDBOX_CONFIG_DIR/.config/opencode"
            cp -r "$HOME/.config/opencode" "$SANDBOX_CONFIG_DIR/.config/opencode"
        fi
    fi

    # Sync .local/share/opencode
    if [ -d "$HOME/.local/share/opencode" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.local/share/opencode" ]; then
            echo "Syncing ~/.local/share/opencode ..."
            mkdir -p "$SANDBOX_CONFIG_DIR/.local/share"
            rm -rf "$SANDBOX_CONFIG_DIR/.local/share/opencode"
            cp -r "$HOME/.local/share/opencode" "$SANDBOX_CONFIG_DIR/.local/share/opencode"
        fi
    fi

    # Sync .cache/opencode (isolated from host cache)
    if [ -d "$HOME/.cache/opencode" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.cache/opencode" ]; then
            echo "Syncing ~/.cache/opencode ..."
            mkdir -p "$SANDBOX_CONFIG_DIR/.cache"
            rm -rf "$SANDBOX_CONFIG_DIR/.cache/opencode"
            cp -r "$HOME/.cache/opencode" "$SANDBOX_CONFIG_DIR/.cache/opencode"
        fi
    fi

    # Sync .local/state/opencode (model selection, favorites, history)
    if [ -d "$HOME/.local/state/opencode" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.local/state/opencode" ]; then
            echo "Syncing ~/.local/state/opencode ..."
            mkdir -p "$SANDBOX_CONFIG_DIR/.local/state"
            rm -rf "$SANDBOX_CONFIG_DIR/.local/state/opencode"
            cp -r "$HOME/.local/state/opencode" "$SANDBOX_CONFIG_DIR/.local/state/opencode"
        fi
    fi

    # Sync .qwen (Qwen Code)
    if [ -d "$HOME/.qwen" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.qwen" ]; then
            echo "Syncing ~/.qwen ..."
            rm -rf "$SANDBOX_CONFIG_DIR/.qwen"
            cp -r "$HOME/.qwen" "$SANDBOX_CONFIG_DIR/.qwen"
        fi
    fi

    # Sync .codex (OpenAI Codex CLI)
    if [ -d "$HOME/.codex" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.codex" ]; then
            echo "Syncing ~/.codex ..."
            rm -rf "$SANDBOX_CONFIG_DIR/.codex"
            cp -r "$HOME/.codex" "$SANDBOX_CONFIG_DIR/.codex"
        fi
    fi

    # Sync .gemini (Google Gemini CLI)
    if [ -d "$HOME/.gemini" ]; then
        if [ "$force" = true ] || [ ! -d "$SANDBOX_CONFIG_DIR/.gemini" ]; then
            echo "Syncing ~/.gemini ..."
            rm -rf "$SANDBOX_CONFIG_DIR/.gemini"
            cp -r "$HOME/.gemini" "$SANDBOX_CONFIG_DIR/.gemini"
        fi
    fi

    # Sync .ai-cli config (AI-CLI unified wrapper)
    mkdir -p "$SANDBOX_CONFIG_DIR/.ai-cli"
    if [ -f "$HOME/.ai-cli/config.json" ]; then
        if [ "$force" = true ] || [ ! -f "$SANDBOX_CONFIG_DIR/.ai-cli/config.json" ]; then
            echo "Syncing ~/.ai-cli/config.json ..."
            cp "$HOME/.ai-cli/config.json" "$SANDBOX_CONFIG_DIR/.ai-cli/"
        fi
    fi
    # .env from sandbox project directory (resolve symlinks)
    local src="$0"
    while [ -L "$src" ]; do
        local dir="$(cd "$(dirname "$src")" && pwd)"
        src="$(readlink "$src")"
        [[ $src != /* ]] && src="$dir/$src"
    done
    local script_path="$(cd "$(dirname "$src")" && pwd)"
    if [ -f "$script_path/.ai-cli.env" ]; then
        if [ "$force" = true ] || [ ! -f "$SANDBOX_CONFIG_DIR/.ai-cli/.env" ]; then
            echo "Syncing .ai-cli.env ..."
            cp "$script_path/.ai-cli.env" "$SANDBOX_CONFIG_DIR/.ai-cli/.env"
        fi
    fi

    # Copy fresh credentials from Keychain (always sync credentials)
    if command -v security >/dev/null 2>&1; then
        CREDS=$(security find-generic-password -s "Claude Code-credentials" -w 2>/dev/null)
        if [ -n "$CREDS" ]; then
            mkdir -p "$SANDBOX_CONFIG_DIR/.claude"
            echo "$CREDS" > "$SANDBOX_CONFIG_DIR/.claude/.credentials.json"
            chmod 600 "$SANDBOX_CONFIG_DIR/.claude/.credentials.json"
            echo "Synced credentials from Keychain"
        fi
    fi

    # Mark sandbox as initialized
    touch "$SANDBOX_CONFIG_DIR/.initialized"
    echo "‚úÖ Sandbox config synced to $SANDBOX_CONFIG_DIR"
}

# Function to resolve and create a git worktree
resolve_and_create_worktree() {
    local branch_or_path="$1"
    local target_path=""

    # Path Resolution Logic: absolute path or relative to parent
    if [[ "$branch_or_path" == /* ]] || [[ "$branch_or_path" == ../* ]]; then
        target_path="$branch_or_path"
    else
        # Auto-generate path: .worktrees/${branch//\//-}
        local safe_branch="${branch_or_path//\//-}"
        target_path=".worktrees/$safe_branch"
    fi

    # Worktree Creation Logic
    if [[ -d "$target_path" ]]; then
        # If exists: use it as-is
        :
    else
        # Check if branch exists in git (remote)
        if git branch -r | grep -q "origin/$branch_or_path"; then
            # If branch exists, add worktree from it
            if ! git worktree add "$target_path" "$branch_or_path"; then
                echo "Error: Failed to create worktree at $target_path for branch $branch_or_path" >&2
                exit 1
            fi
        else
            # If branch NOT exists, fallback to HEAD
            echo "Branch $branch_or_path not found in origin, falling back to HEAD" >&2
            if ! git worktree add "$target_path" HEAD; then
                echo "Error: Failed to create worktree at $target_path from HEAD" >&2
                exit 1
            fi
        fi
    fi

    # Return the absolute path
    echo "$(cd "$target_path" && pwd)"
}

# Handle sync-config mode
if [[ "$SYNC_CONFIG" == true ]]; then
    sync_sandbox_config
    exit 0
fi

# Handle worktree creation and path resolution
WORKTREE_PATH=""
if [[ -n "$WORKTREE_BRANCH" ]]; then
    # Resolve script source to absolute path before changing directory
    if [[ "$0" == /* ]]; then
        export SCRIPT_SOURCE="$0"
    else
        export SCRIPT_SOURCE="$(pwd)/$0"
    fi
    
    WORKTREE_PATH=$(resolve_and_create_worktree "$WORKTREE_BRANCH")
    echo "Using worktree: $WORKTREE_PATH"
    cd "$WORKTREE_PATH" || exit 1
fi

# Handle remove mode
if [[ "$REMOVE_IMAGE" == true ]]; then
    HASH_FILE=".claude-code-sandbox-hash"
    
    if [[ ! -f "$SANDBOX_FILE" ]]; then
        echo "No workspace image to remove (no .claude-code-sandbox file found)"
        exit 0
    fi
    
    IMAGE_TO_REMOVE=$(cat "$SANDBOX_FILE")
    echo "=== Removing Claude Code Sandbox Workspace ==="
    echo "Image to remove: $IMAGE_TO_REMOVE"
    echo ""
    
    # Check if image exists
    if [[ -n "$(docker images -q $IMAGE_TO_REMOVE 2>/dev/null)" ]]; then
        echo "Removing Docker image..."
        if docker rmi "$IMAGE_TO_REMOVE"; then
            echo "‚úÖ Successfully removed image: $IMAGE_TO_REMOVE"
        else
            echo "‚ùå Failed to remove image: $IMAGE_TO_REMOVE"
            echo "   The image might be in use by a running container"
            exit 1
        fi
    else
        echo "‚ö†Ô∏è  Image not found in Docker: $IMAGE_TO_REMOVE"
    fi
    
    # Remove state files
    echo ""
    echo "Removing state files..."
    rm -f "$SANDBOX_FILE"
    echo "‚úÖ Removed .claude-code-sandbox"
    
    if [[ -f "$HASH_FILE" ]]; then
        rm -f "$HASH_FILE"
        echo "‚úÖ Removed .claude-code-sandbox-hash"
    fi
    
    echo ""
    echo "‚úÖ Workspace cleanup complete!"
    exit 0
fi

# Check if tools are specified without --build
if [[ "$BUILD_IMAGE" != true && -n "$INSTALL_TOOLS" ]]; then
    echo "Error: Tools can only be installed with --build flag"
    echo "Usage: $0 --build --install='plugin@version,plugin@version'"
    echo "Examples:"
    echo "  $0 --build --install='python@3.12.8,golang@1.21.5'"
    echo "  $0 --build --install='terraform@1.5.7,maven@3.9.6,kubectl@1.28.0'"
    echo "This ensures tools are installed at build time, not runtime"
    exit 1
fi

# Check for .tool-versions file if --build is specified but no --install
if [[ "$BUILD_IMAGE" == true && -z "$INSTALL_TOOLS" && -f ".tool-versions" ]]; then
    echo "Found .tool-versions file, parsing for tool installation..."
    # Parse .tool-versions file and convert to comma-separated format
    TOOL_VERSIONS_CONTENT=""
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Skip empty lines and comments
        if [[ -n "$line" && ! "$line" =~ ^[[:space:]]*# ]]; then
            # Extract plugin and version
            read -r plugin version <<< "$line"
            if [[ -n "$plugin" && -n "$version" ]]; then
                if [[ -n "$TOOL_VERSIONS_CONTENT" ]]; then
                    TOOL_VERSIONS_CONTENT="$TOOL_VERSIONS_CONTENT,$plugin@$version"
                else
                    TOOL_VERSIONS_CONTENT="$plugin@$version"
                fi
            fi
        fi
    done < ".tool-versions"
    
    if [[ -n "$TOOL_VERSIONS_CONTENT" ]]; then
        INSTALL_TOOLS="$TOOL_VERSIONS_CONTENT"
        echo "Installing tools from .tool-versions: $INSTALL_TOOLS"
    fi
fi

# Get the directory where this script is located (handles symlinks, portable)
SCRIPT_SOURCE="${SCRIPT_SOURCE:-$0}"
while [ -L "$SCRIPT_SOURCE" ]; do
    SCRIPT_DIR="$(cd "$(dirname "$SCRIPT_SOURCE")" && pwd)"
    SCRIPT_SOURCE="$(readlink "$SCRIPT_SOURCE")"
    [[ $SCRIPT_SOURCE != /* ]] && SCRIPT_SOURCE="$SCRIPT_DIR/$SCRIPT_SOURCE"
done
SCRIPT_DIR="$(cd "$(dirname "$SCRIPT_SOURCE")" && pwd)"

# Check if base image needs to be built/updated
BASE_IMAGE_EXISTS="$(docker images -q $BASE_IMAGE_NAME 2> /dev/null)"
if [[ -z "$BASE_IMAGE_EXISTS" ]] || [[ "$REBUILD_IMAGE" == true ]]; then
    if [[ "$REBUILD_IMAGE" == true ]]; then
        echo "Rebuilding shared base image without cache: $BASE_IMAGE_NAME"
        docker build --no-cache -f "$SCRIPT_DIR/Dockerfile" --target base -t $BASE_IMAGE_NAME "$SCRIPT_DIR"
    else
        echo "Building shared base image: $BASE_IMAGE_NAME"
        docker build -f "$SCRIPT_DIR/Dockerfile" --target base -t $BASE_IMAGE_NAME "$SCRIPT_DIR"
    fi
fi

# Generate content hash for incremental build detection
CONTENT_HASH=$(get_content_hash "$SCRIPT_DIR")
HASH_FILE=".claude-code-sandbox-hash"

# Check if rebuild is needed
NEEDS_REBUILD=false
if [[ "$BUILD_IMAGE" == true ]]; then
    NEEDS_REBUILD=true
    echo "Forced rebuild requested"
elif [[ -n "$INSTALL_TOOLS" ]]; then
    NEEDS_REBUILD=true
    echo "Tools specified, rebuild needed"
elif [[ "$(docker images -q $IMAGE_NAME 2> /dev/null)" == "" ]]; then
    NEEDS_REBUILD=true
    echo "Image doesn't exist, rebuild needed"
    # Auto-detect .tool-versions for new workspaces
    if [[ -f ".tool-versions" && -z "$INSTALL_TOOLS" ]]; then
        echo "Found .tool-versions file, parsing for tool installation..."
        # Parse .tool-versions file and convert to comma-separated format
        TOOL_VERSIONS_CONTENT=""
        while IFS= read -r line || [[ -n "$line" ]]; do
            # Skip empty lines and comments
            if [[ -n "$line" && ! "$line" =~ ^[[:space:]]*# ]]; then
                # Extract plugin and version
                read -r plugin version <<< "$line"
                if [[ -n "$plugin" && -n "$version" ]]; then
                    if [[ -n "$TOOL_VERSIONS_CONTENT" ]]; then
                        TOOL_VERSIONS_CONTENT="$TOOL_VERSIONS_CONTENT,$plugin@$version"
                    else
                        TOOL_VERSIONS_CONTENT="$plugin@$version"
                    fi
                fi
            fi
        done < ".tool-versions"
        
        if [[ -n "$TOOL_VERSIONS_CONTENT" ]]; then
            INSTALL_TOOLS="$TOOL_VERSIONS_CONTENT"
            echo "Installing tools from .tool-versions: $INSTALL_TOOLS"
        fi
    fi
elif [[ ! -f "$HASH_FILE" ]] || [[ "$(cat "$HASH_FILE" 2>/dev/null)" != "$CONTENT_HASH" ]]; then
    NEEDS_REBUILD=true
    echo "Configuration changed, incremental rebuild needed"
fi

# Build workspace-specific image if needed
if [[ "$NEEDS_REBUILD" == true ]]; then
    echo "Building workspace image: $IMAGE_NAME"
    BUILD_ARGS="--build-arg BASE_IMAGE=$BASE_IMAGE_NAME"
    if [ -n "$INSTALL_TOOLS" ]; then
        BUILD_ARGS="$BUILD_ARGS --build-arg INSTALL_TOOLS='$INSTALL_TOOLS'"
        echo "Installing tools: $INSTALL_TOOLS"
    fi
    
    # Add --no-cache flag if rebuild is requested
    if [[ "$REBUILD_IMAGE" == true ]]; then
        echo "Forcing full rebuild without cache..."
        BUILD_ARGS="--no-cache $BUILD_ARGS"
    fi
    
    docker build $BUILD_ARGS -f "$SCRIPT_DIR/Dockerfile" --target workspace -t $IMAGE_NAME "$SCRIPT_DIR"
    
    # Save content hash for future incremental builds
    echo "$CONTENT_HASH" > "$HASH_FILE"
else
    echo "No changes detected, using existing image: $IMAGE_NAME"
fi


# Check for Claude configuration directories
CLAUDE_CONFIG=""

# Auto-sync sandbox config on first run only (check for .initialized marker)
if [ ! -f "$SANDBOX_CONFIG_DIR/.initialized" ]; then
    echo "First run detected - syncing configs to sandbox..."
    sync_sandbox_config false  # false = don't overwrite existing configs
fi

# Mount sandbox configs (persistent, protects host files)
if [ -d "$SANDBOX_CONFIG_DIR/.claude" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.claude:/home/node/.claude"
    echo "Using sandbox config: .claude"
fi

if [ -d "$SANDBOX_CONFIG_DIR/.config/claude" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.config/claude:/home/node/.config/claude"
    echo "Using sandbox config: .config/claude"
fi

if [ -d "$SANDBOX_CONFIG_DIR/.anthropic" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.anthropic:/home/node/.anthropic"
    echo "Using sandbox config: .anthropic"
fi

# Check for .m2 directory (Maven)
if [ -d "$HOME/.m2" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.m2:/home/node/.m2"
    echo "Mounting Maven config from $HOME/.m2"
fi

# Check for .gradle directory (Gradle)
if [ -d "$HOME/.gradle" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.gradle:/home/node/.gradle"
    echo "Mounting Gradle config from $HOME/.gradle"
fi

# Check for .npm directory (Node.js)
if [ -d "$HOME/.npm" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.npm:/home/node/.npm"
    echo "Mounting npm cache from $HOME/.npm"
fi

# Check for .cache directory (covers pip, yarn, pnpm, go-build, deno, composer, etc.)
if [ -d "$HOME/.cache" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.cache:/home/node/.cache"
    echo "Mounting cache directory from $HOME/.cache"
fi

# Check for .pnpm-store directory (pnpm global store)
if [ -d "$HOME/.pnpm-store" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.pnpm-store:/home/node/.pnpm-store"
    echo "Mounting pnpm store from $HOME/.pnpm-store"
fi

# Check for .cargo directory (Rust)
if [ -d "$HOME/.cargo" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.cargo:/home/node/.cargo"
    echo "Mounting Cargo config from $HOME/.cargo"
fi

# Check for go directory (Go modules)
if [ -d "$HOME/go" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/go:/home/node/go"
    echo "Mounting Go workspace from $HOME/go"
fi


# Check for .gem directory (Ruby gems)
if [ -d "$HOME/.gem" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.gem:/home/node/.gem"
    echo "Mounting Ruby gems from $HOME/.gem"
fi

# Check for .bundle directory (Ruby bundler)
if [ -d "$HOME/.bundle" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.bundle:/home/node/.bundle"
    echo "Mounting Ruby bundle config from $HOME/.bundle"
fi


# Check for .nuget directory (NuGet packages)
if [ -d "$HOME/.nuget" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.nuget:/home/node/.nuget"
    echo "Mounting NuGet packages from $HOME/.nuget"
fi


# Check for .bun directory (Bun)
if [ -d "$HOME/.bun" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/.bun:/home/node/.bun"
    echo "Mounting Bun config from $HOME/.bun"
fi

# Mount sandbox .claude.json
if [ -f "$SANDBOX_CONFIG_DIR/.claude.json" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.claude.json:/home/node/.claude.json"
    echo "Using sandbox config: .claude.json"
fi

# Mount sandbox opencode config
if [ -d "$SANDBOX_CONFIG_DIR/.config/opencode" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.config/opencode:/home/node/.config/opencode"
    echo "Using sandbox config: .config/opencode"
fi

# Mount sandbox opencode data
if [ -d "$SANDBOX_CONFIG_DIR/.local/share/opencode" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.local/share/opencode:/home/node/.local/share/opencode"
    echo "Using sandbox config: .local/share/opencode"
fi

# Mount sandbox Qwen Code config
if [ -d "$SANDBOX_CONFIG_DIR/.qwen" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.qwen:/home/node/.qwen"
    echo "Using sandbox config: .qwen"
fi

# Check for worktree path and mount if set
WORKTREE_MOUNT=""
if [ -n "$WORKTREE_PATH" ]; then
    WORKTREE_MOUNT="-v $WORKTREE_PATH:/workspace"
    echo "Mounting worktree from $WORKTREE_PATH"
fi

# Mount sandbox Codex config (OpenAI Codex CLI)
if [ -d "$SANDBOX_CONFIG_DIR/.codex" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.codex:/home/node/.codex"
    echo "Using sandbox config: .codex"
fi

# Mount sandbox Gemini config (Google Gemini CLI)
if [ -d "$SANDBOX_CONFIG_DIR/.gemini" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.gemini:/home/node/.gemini"
    echo "Using sandbox config: .gemini"
fi

# Mount AI-CLI config files (not the whole dir - repo is cloned there)
if [ -f "$SANDBOX_CONFIG_DIR/.ai-cli/config.json" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.ai-cli/config.json:/home/node/.ai-cli/config.json"
    echo "Using sandbox config: .ai-cli/config.json"
fi
if [ -f "$SANDBOX_CONFIG_DIR/.ai-cli/.env" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.ai-cli/.env:/home/node/.ai-cli/.env"
    echo "Using sandbox config: .ai-cli/.env"
fi

# Mount sandbox opencode cache (overrides host ~/.cache/opencode)
if [ -d "$SANDBOX_CONFIG_DIR/.cache/opencode" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.cache/opencode:/home/node/.cache/opencode"
    echo "Using sandbox config: .cache/opencode"
fi

# Mount sandbox opencode state (model selection, favorites, history)
if [ -d "$SANDBOX_CONFIG_DIR/.local/state/opencode" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $SANDBOX_CONFIG_DIR/.local/state/opencode:/home/node/.local/state/opencode"
    echo "Using sandbox config: .local/state/opencode"
fi

# Check for basic-memory directory (basic-memory MCP server)
if [ -d "$HOME/basic-memory" ]; then
    CLAUDE_CONFIG="$CLAUDE_CONFIG -v $HOME/basic-memory:/home/node/basic-memory"
    echo "Mounting basic-memory MCP server from $HOME/basic-memory"
fi

# Handle workspace mounting
# Note: handled via WORKSPACE_MOUNT to support paths with spaces consistently
WORKSPACE_MOUNT="$(pwd):/workspace"

# Check for .beads directory (beads task management)
# Note: handled separately via BEADS_MOUNT to support paths with spaces
BEADS_MOUNT=""
if [ -d "$(pwd)/.beads" ]; then
    BEADS_MOUNT="$(pwd)/.beads:/workspace/.beads"
    echo "Mounting beads task directory from $(pwd)/.beads"
fi

# Add Docker socket mounting if Docker flag is enabled
DOCKER_MOUNT=""
if [ "$DOCKER_ENABLED" = true ]; then
    if [ -S "/var/run/docker.sock" ]; then
        DOCKER_MOUNT="-v /var/run/docker.sock:/var/run/docker.sock"
        echo "Mounting Docker socket for container access"
    else
        echo "Warning: Docker socket not found at /var/run/docker.sock"
        echo "Docker commands may not work inside the container"
    fi
fi

if [ -z "$CLAUDE_CONFIG" ]; then
    echo "Warning: No configuration directories found"
fi

# Check if we have a TTY or if non-interactive mode is requested
if [ -t 0 ] || [ "$NON_INTERACTIVE" = true ]; then
    if [ "$SHELL_MODE" = true ]; then
        # Run interactive shell instead of Claude Code
        docker run -it --rm \
            --user node \
            ${WORKTREE_MOUNT:--v "$(pwd):/workspace"} \
            ${BEADS_MOUNT:+-v "$BEADS_MOUNT"} \
            $CLAUDE_CONFIG \
            $DOCKER_MOUNT \
             \
            -e TERM="$TERM" \
            --init \
            "$IMAGE_NAME" \
            bash -c "source ~/.asdf/asdf.sh 2>/dev/null || true; exec bash"
    elif [ "$NON_INTERACTIVE" = true ]; then
        # Run non-interactive command with asdf support
        docker run --rm \
            --user node \
            ${WORKTREE_MOUNT:--v "$(pwd):/workspace"} \
            ${BEADS_MOUNT:+-v "$BEADS_MOUNT"} \
            $CLAUDE_CONFIG \
            $DOCKER_MOUNT \
             \
            --init \
            "$IMAGE_NAME" \
            bash -c "export PATH=\"\$HOME/.npm-global/bin:\$HOME/.local/bin:\$PATH\"; source ~/.asdf/asdf.sh 2>/dev/null || true; $*"
    else
        # Run the container with current directory mounted as workspace
        docker run -it --rm \
            --user node \
            ${WORKTREE_MOUNT:--v "$(pwd):/workspace"} \
            ${BEADS_MOUNT:+-v "$BEADS_MOUNT"} \
            $CLAUDE_CONFIG \
            $DOCKER_MOUNT \
             \
            -e TERM="$TERM" \
            --init \
            "$IMAGE_NAME" \
            bash -c "source ~/.asdf/asdf.sh 2>/dev/null || true; if ! command -v node >/dev/null 2>&1; then echo 'No Node.js found, installing LTS...'; asdf plugin add nodejs 2>/dev/null || true; asdf install nodejs lts; asdf global nodejs lts; fi; claude-wrapper --dangerously-skip-permissions $*"
    fi
else
    echo "Error: This script requires an interactive terminal (TTY)."
    echo "Please run this script from a regular terminal, not from within another program."
    echo "The script is designed to launch an interactive Claude session."
    echo "Use -n or --non-interactive to run commands without TTY."
    exit 1
fi